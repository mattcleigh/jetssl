# @package _global_

defaults:
  - override /datamodule: shlomi.yaml
  - override /model: vertexer.yaml
  - override /callbacks: finetune.yaml

# Faster warmup
model:
  scheduler:
    warmup_steps: 5000

# Dont train for too long
trainer:
  max_epochs: null
  max_steps: 50_000

# Key parameters for fine-tuning
n_jets: 600_000 # Max in shomi

# Never finetune on the full dataset, always 1 file and n_jets
datamodule:
  train_set:
    n_files: 1
    n_jets_total: ${n_jets}
  val_set:
    n_files: 1
    n_jets_total: ${n_jets}
  test_set:
    n_files: 1
  loader_config:
    batch_size: 1024 # Shlomi is only 15 particles, we can handle that
    num_workers: 2

# Bookkeeping
project_name: jetssl_finetune
network_name: vertexer_${n_jets}

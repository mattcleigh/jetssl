# @package _global_

defaults:
  - override /datamodule: shlomi.yaml
  - override /model: vertexer.yaml
  - override /callbacks: finetune.yaml

# Faster warmup
model:
  scheduler:
    warmup_steps: 5000

# Dont train for too long
trainer:
  max_epochs: null
  max_steps: 50_000

# We use the ARI performance on b jets for early stopping
callbacks:
  early_stopping:
    monitor: valid/ari_2
    mode: max

# Key parameters for fine-tuning
n_jets: 600_000 # Max in shomi

# Never finetune on the full dataset, always 1 file and n_jets
# For shlomi use full val and test
datamodule:
  train_set:
    n_files: 1
    n_jets_total: ${n_jets}
  loader_config:
    batch_size: 500
    num_workers: 2

# Bookkeeping
project_name: jetssl_finetune
network_name: vertexer_${n_jets}

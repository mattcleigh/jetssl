# @package _global_

defaults:
  - override /datamodule: jetclass.yaml
  - override /model: jetclassifier.yaml
  - override /callbacks: finetune.yaml

# Faster warmup
model:
  scheduler:
    warmup_steps: 5000

# Dont train for too long
trainer:
  max_epochs: null
  max_steps: 50_000

# Key parameters for fine-tuning
n_jets: 1000000 # Number of jets per class

# Never finetune on the full dataset, always 1 file and n_jets
datamodule:
  train_set:
    n_files: 1
    n_jets: ${n_jets}
  val_set:
    n_files: 1
    n_jets: ${n_jets}
  test_set:
    n_files: 1
  loader_config:
    batch_size: 500 # Smaller because some setups have 1000 jets
    num_workers: 2

# Bookkeeping
project_name: jetssl_finetuning
network_name: classifier_${n_jets}

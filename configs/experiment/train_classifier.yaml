# @package _global_

defaults:
  - override /datamodule: jetclass.yaml
  - override /model: jetclassifier.yaml
  - override /callbacks: finetune.yaml

# Dont train for too long
trainer:
  max_epochs: null
  max_steps: 100000

# Key parameters for fine-tuning
n_jets: 10000 # Number of jets per class

# Never finetune on the full dataset, always 1 file and n_jets
datamodule:
  train_set:
    n_files: 1
  val_set:
    n_files: 1
  test_set:
    n_files: 1
  loader_config:
    batch_size: 500 # Smaller because some setups have 1000 jets
    num_workers: 1 # Tiny datasets will break with more workers

# For faster training
precision: medium
compile: null

# Bookkeeping
project_name: jetssl_finetuning
network_name: classifier_${n_jets}

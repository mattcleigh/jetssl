backbone_finetune:
  _target_: src.models.finetuning.CatchupToLR
  unfreeze_at_step: 5000
  catchup_steps: 5000

best_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${paths.full_path}/checkpoints
  filename: best
  monitor: valid/total_loss
  mode: min
  save_weights_only: True
  auto_insert_metric_name: False
  enable_version_counter: False

early_stopping:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: valid/total_loss
  patience: 50
  mode: min

model_summary:
  _target_: pytorch_lightning.callbacks.RichModelSummary
  max_depth: 2

lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: step
